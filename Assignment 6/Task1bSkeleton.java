package ex.ex06;

public class Task1bSkeleton 
{
	final static String[] documents= {
			"Workshop on Contextual Information Access, Seeking and Retrieval Evaluation The main purpose of this workshop is to bring together IR researchers working on or interested in the evaluation of approaches to contextual information access, seeking and retrieval, and let them to share their latest research results, to express their opinions on the related issues, and to promote discussion on the future directions of evaluation.",
			"Supporting Complex Search Tasks - ECIR 2015 Workshop There is broad consensus in the field of IR that search is complex in many use cases and applications, both on the web and in domain specific collections, and both professionally and in our daily life. Yet our understanding of complex search tasks, in comparison to simple look up tasks, is fragmented at best. The workshop addressed the many open research questions: What are the obvious use cases and applications of complex search? What are essential features of work tasks and search tasks to take into account? And how do these evolve over time? With a multitude of information, varying from introductory to specialized, and from authoritative to speculative or opinionated, when to show what sources of information? How does the information seeking process evolve and what are relevant differences between diferent stages? With complex task and search process management, blending searching, browsing, and recommendations, and supporting exploratory search to sense making and analytics, UI and UX design pose an over-constrained challenge. How do we know that our approach is any good? Supporting complex search task requires new collaborations across the whole held of IR, and the proposed workshop will bring together a diverse group of researchers to work together on one of the greatest challenges of our field.",
			"Applied Distributed Information Retrieval in Enterprise Search Distributed enterprise search as a special case of Distributed Information Retrieval (DIR) is characterized by the need to query multiple repositories in enterprise environments. However, in DIR research there is a lack of publicly available real-world datasets for evaluation purposes. As a result , there is a gap between insights gained from simulated environments and real-world investigations on distributed enterprise search. In this paper, we outline three fundamental issues based on our investigations of a large real-world distributed enterprise search system. We found that (1) the utilization of security features in enterprise repositories, (2) the adaptation of resource description and resource selection for enterprise model, and (3) repository grouping are fundamental real-world issues. We hypothesize that a better understanding of these issues will contribute to improve the distributed enterprise search and better support complex search tasks in enterprise environments. Based on our experience gained from a real-world system, we also outline needed steps to cope with these issues.",
			"Diversity, Assortment, Dissimilarity, Variety: A Study of Diversity Measures Using Low Level Features for Video Retrieval In this paper we present a number of methods for re-ranking video search results in order to introduce diversity into the set of search results. The usefulness of these approaches is evaluated in comparison with similarity based measures, for the TRECVID 2007 collection and tasks [11]. For the MAP of the search results we find that some of our approaches perform as well as similarity based methods. We also find that some of these results can improve the P@N values for some of the lower N values. The most successful of these approaches was then implemented in an interactive search system for the TRECVID 2008 interactive search tasks. The responses from the users indicate that they find the more diverse search results extremely useful.",
			"Bibliometrics in Online Book Discussions: Lessons for Complex Search Tasks Online book discussion forums provide rich information on how readers think about and describe books, how books are related to other books and how people search for and recommend books. Within the Social Book Search (SBS) Lab at CLEF we analyse book search requests on the LibraryThing forums and find several types of complex search tasks where bibliometrics naturally combines with information retrieval. This paper explores how book search information needs in online book discussions are related to bibliometric analysis and how the structure of book citations in reviews and discussions can support complex book search tasks where users want to go beyond topical relevance ranking and see how books are related to each other and particularly to the books and authors they know.",
			"Detecting the Eureka Effect in Complex Search In search tasks that show a high complexity, users with zero or little background knowledge usually need to go through a learning curve to accomplish the tasks. In the context of patent prior art finding, we introduce a novel notion of Eureka effect in complex search tasks that leverages the sudden change of user's perceived relevance observable in the log data. Eureka effect refers to the common experience of sudden understanding a previously incomprehensible problem or concept. We employ non-parametric regression to model the learning curve that exists in learning-intensive search tasks and report our preliminary findings in observing the Eureka effect in patent prior art finding.",
			"First Workshop on Supporting Complex Search Tasks There is broad consensus in the field of IR that search is complex in many use cases and applications, both on the Web and in domain specific collections, and both professionally and in our daily life. Yet our understanding of complex search tasks, in comparison to simple look up tasks, is fragmented at best. The workshop addressed the many open research questions: What are the obvious use cases and applications of complex search? What are essential features of work tasks and search tasks to take into account? And how do these evolve over time? With a multitude of information, varying from introductory to specialized, and from authoritative to speculative or opinionated, when to show what sources of information? How does the information seeking process evolve and what are relevant differences between different stages? With complex task and search process management, blending searching, browsing, and recommendations, and supporting exploratory search to sensemaking and analytics, UI and UX design pose an over-constrained challenge. How do we know that our approach is any good? Supporting complex search task requires new collaborations across the whole field of IR, and the proposed workshop will bring together a diverse group of researchers to work together on one of the greatest challenges of our field.",
			"Supervised Local Contexts Aggregation for Effective Session Search Existing research on web search has mainly focused on the optimization and evaluation of single queries. However, in some complex search tasks, users usually need to interact with the search engine multiple times before their needs can be satisfied, the process of which is known as session search. The key to this problem relies on how to utilize the session context from preceding interactions to improve the search accuracy for the current query. Unfortunately, existing research on this topic only formulated limited modeling for session contexts, which in fact can exhibit considerable variations. In this paper, we propose Supervised Local Context Aggregation (SLCA) as a principled framework for complex session context modeling. In SLCA, the global session context is formulated as the combination of local contexts between consecutive interactions. These local contexts are further weighted by multiple weighting hypotheses. Finally, a supervised ranking aggregation is adopted for effective optimization. Extensive experiments on TREC11/12 session track show that our proposed SLCA algorithm outperforms many other session search methods, and achieves the state-of-the-art results.",
			"Promoting User Engagement and Learning in Amorphous Search Tasks Much research in information retrieval (IR) focuses on optimization of the rank of relevant retrieval results for single shot ad hoc IR tasks. Relatively little research has been carried out on user engagement to support more complex search tasks. We seek to improve user engagement for IR tasks by providing richer representation of retrieved information. It is our expectation that this strategy will promote implicit learning within search activities. Specifically, we plan to explore methods of finding semantic concepts within retrieved documents, with the objective of creating improved document surrogates. Further, we would like to study search effectiveness in terms of different facets such as the user's search experience, satisfaction, engagement and learning. We intend to investigate this in an experimental study, where our richer document representations are compared with the traditional document surrogates for the same user queries.",
			"Differences in the Use of Search Assistance for Tasks of Varying Complexity In this paper, we study how users interact with a search assistance tool while completing tasks of varying complexity. We designed a novel tool referred to as the search guide (SG) that displays the search trails (queries issued, results clicked, pages bookmarked) from three previous users who completed the task. We report on a laboratory study with 48 participants that investigates different factors that may influence user interaction with the SG and the effects of the SG on different outcome measures. Participants were asked to find and bookmark pages for four tasks of varying complexity and the SG was made available to half the participants. We collected log data and conducted retrospective stimulated recall interviews to learn about participants' use of the SG. Our results suggest the following trends. First, interaction with the SG was greater for more complex tasks. Second, the a priori determinability of the task (i.e., whether the task was perceived to be well-defined) helped predict whether participants gained a bookmark from the SG. Third, participants who interacted with the SG, but did not gain a bookmark, felt less system support than those who gained a bookmark and those who did not interact. Finally, a qualitative analysis of our interviews suggests differences in motivation and benefits from SG use for different levels of task complexity. Our findings extend prior research on search assistance tools and provide insights for the design of systems to help users with complex search tasks.",
			"Position Paper: Promoting User Engagement and Learning in Search Tasks By Effective Document Representation Much research in information retrieval (IR) focuses on optimization of the rank of relevant retrieval results for single shot ad hoc IR tasks with straightforward information needs. Relatively little research has been carried out to study and support user learning and engagement for more complex search tasks. We introduce an approach intended to improve topical knowledge of a user while undertaking IR tasks. Specifically, we propose to explore methods of finding useful and informative textual units (semantic concepts) within retrieved documents, with the objective of creating improved document surrogates for presentation within the search process. We hypothesize that this strategy will promote improved implicit learning within search activities. We believe that the richer document representations proposed in the paper would help to promote engagement, understanding and learning as compared to more traditional search engine document snippets. We propose a framework for holistic evaluation of our proposed document representations and their use in search.",
		};

}